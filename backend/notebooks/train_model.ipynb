{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal Case Outcome Prediction - Model Training\n",
    "\n",
    "This notebook loads, cleans, and trains models on legal case data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:12:22.357818Z",
     "iopub.status.busy": "2025-11-24T21:12:22.357409Z",
     "iopub.status.idle": "2025-11-24T21:12:26.093538Z",
     "shell.execute_reply": "2025-11-24T21:12:26.093286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Fix for importlib metadata issue in conda environments\n",
    "# This patches both importlib.metadata and importlib_metadata to handle None metadata\n",
    "import sys\n",
    "import importlib.metadata\n",
    "import importlib_metadata\n",
    "\n",
    "# Patch importlib.metadata.version (used by datasets/config.py)\n",
    "_original_version = importlib.metadata.version\n",
    "def _safe_version(name):\n",
    "    try:\n",
    "        result = _original_version(name)\n",
    "        if result is None:\n",
    "            # Return a valid version string instead of 'unknown'\n",
    "            return '0.0.0'\n",
    "        return result\n",
    "    except Exception:\n",
    "        # Return a valid version string for packaging.version.parse()\n",
    "        return '0.0.0'\n",
    "\n",
    "importlib.metadata.version = _safe_version\n",
    "sys.modules['importlib.metadata'].version = _safe_version\n",
    "\n",
    "# Patch importlib_metadata.distribution\n",
    "_original_distribution = importlib_metadata.distribution\n",
    "def _safe_distribution(name):\n",
    "    try:\n",
    "        dist = _original_distribution(name)\n",
    "        if hasattr(dist, 'metadata') and dist.metadata is None:\n",
    "            class MockDist:\n",
    "                metadata = {'Version': 'unknown'}\n",
    "                @property\n",
    "                def version(self):\n",
    "                    return 'unknown'\n",
    "            return MockDist()\n",
    "        return dist\n",
    "    except Exception:\n",
    "        class MockDist:\n",
    "            metadata = {'Version': 'unknown'}\n",
    "            @property\n",
    "            def version(self):\n",
    "                return 'unknown'\n",
    "        return MockDist()\n",
    "\n",
    "importlib_metadata.distribution = _safe_distribution\n",
    "sys.modules['importlib_metadata'].distribution = _safe_distribution\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set paths\n",
    "BASE_DIR = Path('../')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load CSV Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:12:26.109848Z",
     "iopub.status.busy": "2025-11-24T21:12:26.109669Z",
     "iopub.status.idle": "2025-11-24T21:12:26.532459Z",
     "shell.execute_reply": "2025-11-24T21:12:26.532202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockets shape: (73000, 58)\n",
      "Opinions shape: (18500, 8)\n",
      "\n",
      "Dockets columns: ['resource_uri', 'id', 'court', 'court_id', 'original_court_info', 'idb_data', 'clusters', 'audio_files', 'assigned_to', 'referred_to', 'absolute_url', 'date_created', 'date_modified', 'source', 'appeal_from_str', 'assigned_to_str', 'referred_to_str', 'panel_str', 'date_last_index', 'date_cert_granted', 'date_cert_denied', 'date_argued', 'date_reargued', 'date_reargument_denied', 'date_filed', 'date_terminated', 'date_last_filing', 'case_name_short', 'case_name', 'case_name_full', 'slug', 'docket_number', 'docket_number_core', 'docket_number_raw', 'federal_dn_office_code', 'federal_dn_case_type', 'federal_dn_judge_initials_assigned', 'federal_dn_judge_initials_referred', 'federal_defendant_number', 'pacer_case_id', 'cause', 'nature_of_suit', 'jury_demand', 'jurisdiction_type', 'appellate_fee_status', 'appellate_case_type_information', 'mdl_status', 'filepath_ia', 'filepath_ia_json', 'ia_upload_failure_count', 'ia_needs_upload', 'ia_date_first_change', 'date_blocked', 'blocked', 'appeal_from', 'parent_docket', 'tags', 'panel']\n",
      "\n",
      "Opinions columns: ['docket_id', 'case_name', 'court', 'date_filed', 'opinion_id', 'opinion_type', 'opinion_text', 'outcome']\n"
     ]
    }
   ],
   "source": [
    "# Load both CSV files\n",
    "dockets = pd.read_csv(DATA_DIR / 'courtlistener_dockets_partial.csv')\n",
    "opinions = pd.read_csv(DATA_DIR / 'opinions_checkpoint.csv')\n",
    "\n",
    "print(f\"Dockets shape: {dockets.shape}\")\n",
    "print(f\"Opinions shape: {opinions.shape}\")\n",
    "print(f\"\\nDockets columns: {list(dockets.columns)}\")\n",
    "print(f\"\\nOpinions columns: {list(opinions.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge Docket and Opinion Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:12:26.533554Z",
     "iopub.status.busy": "2025-11-24T21:12:26.533481Z",
     "iopub.status.idle": "2025-11-24T21:12:26.565834Z",
     "shell.execute_reply": "2025-11-24T21:12:26.565629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (18500, 10)\n",
      "\n",
      "Missing values:\n",
      "docket_id           0\n",
      "case_name_x         0\n",
      "court_x             0\n",
      "date_filed      18500\n",
      "opinion_id          0\n",
      "opinion_type        0\n",
      "opinion_text        1\n",
      "outcome             0\n",
      "case_name_y         0\n",
      "court_y             0\n",
      "dtype: int64\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docket_id</th>\n",
       "      <th>case_name_x</th>\n",
       "      <th>court_x</th>\n",
       "      <th>date_filed</th>\n",
       "      <th>opinion_id</th>\n",
       "      <th>opinion_type</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>outcome</th>\n",
       "      <th>case_name_y</th>\n",
       "      <th>court_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71884389</td>\n",
       "      <td>Trump v. Orr</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11198703</td>\n",
       "      <td>010combined</td>\n",
       "      <td>Cite as: 607 U. S. ____ (202...</td>\n",
       "      <td>granted</td>\n",
       "      <td>Trump v. Orr</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71735833</td>\n",
       "      <td>Boyd v. Hamm</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11177002</td>\n",
       "      <td>010combined</td>\n",
       "      <td>...</td>\n",
       "      <td>granted</td>\n",
       "      <td>Boyd v. Hamm</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71735833</td>\n",
       "      <td>Boyd v. Hamm</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11177003</td>\n",
       "      <td>010combined</td>\n",
       "      <td>Cite as: 607 U. S. ____ (202...</td>\n",
       "      <td>granted</td>\n",
       "      <td>Boyd v. Hamm</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71735833</td>\n",
       "      <td>Boyd v. Hamm</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11176501</td>\n",
       "      <td>010combined</td>\n",
       "      <td>Cite as: 607 U. S. ____ (202...</td>\n",
       "      <td>granted</td>\n",
       "      <td>Boyd v. Hamm</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71659774</td>\n",
       "      <td>Crawford v. Mississippi</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11171208</td>\n",
       "      <td>010combined</td>\n",
       "      <td>Cite as: 607 U. S. ____ (202...</td>\n",
       "      <td>denied</td>\n",
       "      <td>Crawford v. Mississippi</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v4/cour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docket_id              case_name_x  \\\n",
       "0  71884389             Trump v. Orr   \n",
       "1  71735833             Boyd v. Hamm   \n",
       "2  71735833             Boyd v. Hamm   \n",
       "3  71735833             Boyd v. Hamm   \n",
       "4  71659774  Crawford v. Mississippi   \n",
       "\n",
       "                                             court_x  date_filed  opinion_id  \\\n",
       "0  https://www.courtlistener.com/api/rest/v4/cour...         NaN    11198703   \n",
       "1  https://www.courtlistener.com/api/rest/v4/cour...         NaN    11177002   \n",
       "2  https://www.courtlistener.com/api/rest/v4/cour...         NaN    11177003   \n",
       "3  https://www.courtlistener.com/api/rest/v4/cour...         NaN    11176501   \n",
       "4  https://www.courtlistener.com/api/rest/v4/cour...         NaN    11171208   \n",
       "\n",
       "  opinion_type                                       opinion_text  outcome  \\\n",
       "0  010combined                    Cite as: 607 U. S. ____ (202...  granted   \n",
       "1  010combined                                                ...  granted   \n",
       "2  010combined                    Cite as: 607 U. S. ____ (202...  granted   \n",
       "3  010combined                    Cite as: 607 U. S. ____ (202...  granted   \n",
       "4  010combined                    Cite as: 607 U. S. ____ (202...   denied   \n",
       "\n",
       "               case_name_y                                            court_y  \n",
       "0             Trump v. Orr  https://www.courtlistener.com/api/rest/v4/cour...  \n",
       "1             Boyd v. Hamm  https://www.courtlistener.com/api/rest/v4/cour...  \n",
       "2             Boyd v. Hamm  https://www.courtlistener.com/api/rest/v4/cour...  \n",
       "3             Boyd v. Hamm  https://www.courtlistener.com/api/rest/v4/cour...  \n",
       "4  Crawford v. Mississippi  https://www.courtlistener.com/api/rest/v4/cour...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract docket_id from dockets (it's in the id column)\n",
    "dockets['docket_id'] = dockets['id'].astype(str)\n",
    "opinions['docket_id'] = opinions['docket_id'].astype(str)\n",
    "\n",
    "# Merge on docket_id\n",
    "df = opinions.merge(\n",
    "    dockets[['docket_id', 'case_name', 'court']],\n",
    "    on='docket_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset shape: {df.shape}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Text Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:12:26.566807Z",
     "iopub.status.busy": "2025-11-24T21:12:26.566740Z",
     "iopub.status.idle": "2025-11-24T21:12:26.806104Z",
     "shell.execute_reply": "2025-11-24T21:12:26.805871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, dataset shape: (18499, 11)\n",
      "\n",
      "Sample cleaned text (first 500 chars):\n",
      "Cite as: 607 U. S. ____ (2025) 1 SUPREME COURT OF THE UNITED STATES _________________ No. 25A319 _________________ DONALD J. TRUMP, PRESIDENT OF THE UNITED STATES, ET AL. v. ASHTON ORR, ET AL. ON APPLICATION FOR STAY [November 6, 2025] This case concerns an Executive Branch policy requiring all new passports to display an individual’s biological sex at birth. The United States District Court for the District of Massachusetts preliminarily enjoined the Government from enforcing the policy, and th\n"
     ]
    }
   ],
   "source": [
    "def clean_legal_text(text):\n",
    "    \"\"\"\n",
    "    Clean legal text by removing outcome-revealing words and procedural boilerplate.\n",
    "    Applies tail-scrubbing to last 2000 characters.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Outcome-revealing words to remove\n",
    "    outcome_words = [\n",
    "        'AFFIRMED', 'REVERSED', 'VACATED', 'REMANDED',\n",
    "        'GRANTED', 'DISMISSED', 'DENIED',\n",
    "        'affirmed', 'reversed', 'vacated', 'remanded',\n",
    "        'granted', 'dismissed', 'denied'\n",
    "    ]\n",
    "    \n",
    "    # Remove outcome words\n",
    "    for word in outcome_words:\n",
    "        text = text.replace(word, '')\n",
    "    \n",
    "    # Tail-scrubbing: clean last 2000 characters\n",
    "    if len(text) > 2000:\n",
    "        tail = text[-2000:]\n",
    "        main_text = text[:-2000]\n",
    "        \n",
    "        # Remove procedural boilerplate patterns from tail\n",
    "        tail = re.sub(r'Judgment\\s+vacated[^.]*\\.', '', tail, flags=re.IGNORECASE)\n",
    "        tail = re.sub(r'and\\s+remanded[^.]*\\.', '', tail, flags=re.IGNORECASE)\n",
    "        tail = re.sub(r'Certiorari\\s+granted[^.]*\\.', '', tail, flags=re.IGNORECASE)\n",
    "        tail = re.sub(r'The\\s+petition\\s+for\\s+rehearing\\s+is\\s+denied[^.]*\\.', '', tail, flags=re.IGNORECASE)\n",
    "        tail = re.sub(r'\\bremanded\\b[^.]*\\.', '', tail, flags=re.IGNORECASE)\n",
    "        tail = re.sub(r'\\bvacated\\b[^.]*\\.', '', tail, flags=re.IGNORECASE)\n",
    "        tail = re.sub(r'\\breversed\\b[^.]*\\.', '', tail, flags=re.IGNORECASE)\n",
    "        tail = re.sub(r'\\baffirmed\\b[^.]*\\.', '', tail, flags=re.IGNORECASE)\n",
    "        \n",
    "        text = main_text + tail\n",
    "    else:\n",
    "        # Apply same cleaning to entire text if shorter than 2000 chars\n",
    "        text = re.sub(r'Judgment\\s+vacated[^.]*\\.', '', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'and\\s+remanded[^.]*\\.', '', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'Certiorari\\s+granted[^.]*\\.', '', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'The\\s+petition\\s+for\\s+rehearing\\s+is\\s+denied[^.]*\\.', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df['clean_text'] = df['opinion_text'].apply(clean_legal_text)\n",
    "\n",
    "# Remove rows with empty clean_text\n",
    "df = df[df['clean_text'].str.len() > 0]\n",
    "\n",
    "print(f\"After cleaning, dataset shape: {df.shape}\")\n",
    "print(f\"\\nSample cleaned text (first 500 chars):\")\n",
    "print(df['clean_text'].iloc[0][:500] if len(df) > 0 else 'No data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Binary Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:12:26.807118Z",
     "iopub.status.busy": "2025-11-24T21:12:26.807045Z",
     "iopub.status.idle": "2025-11-24T21:12:26.816280Z",
     "shell.execute_reply": "2025-11-24T21:12:26.816068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After labeling, dataset shape: (18100, 12)\n",
      "\n",
      "Label distribution:\n",
      "winlose\n",
      "lose    17467\n",
      "win       633\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_binary_label(outcome):\n",
    "    \"\"\"\n",
    "    Create binary label:\n",
    "    win → {reversed, granted}\n",
    "    lose → {affirmed, denied, dismissed, remanded}\n",
    "    unknown → drop\n",
    "    \"\"\"\n",
    "    if pd.isna(outcome):\n",
    "        return 'unknown'\n",
    "    \n",
    "    outcome_str = str(outcome).lower().strip()\n",
    "    \n",
    "    # Win cases\n",
    "    if 'reversed' in outcome_str or 'granted' in outcome_str:\n",
    "        return 'win'\n",
    "    \n",
    "    # Lose cases\n",
    "    if 'affirmed' in outcome_str or 'denied' in outcome_str or \\\n",
    "       'dismissed' in outcome_str or 'remanded' in outcome_str:\n",
    "        return 'lose'\n",
    "    \n",
    "    return 'unknown'\n",
    "\n",
    "# Create labels\n",
    "df['winlose'] = df['outcome'].apply(create_binary_label)\n",
    "\n",
    "# Drop unknown labels\n",
    "df = df[df['winlose'] != 'unknown']\n",
    "\n",
    "print(f\"After labeling, dataset shape: {df.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['winlose'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate LegalBERT Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:12:26.817265Z",
     "iopub.status.busy": "2025-11-24T21:12:26.817185Z",
     "iopub.status.idle": "2025-11-24T21:13:53.661141Z",
     "shell.execute_reply": "2025-11-24T21:13:53.660173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LegalBERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2491b29341d04bfc81d8724f67a4a2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embeddings shape: (18100, 768)\n",
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Load LegalBERT model\n",
    "print(\"Loading LegalBERT model...\")\n",
    "model = SentenceTransformer('nlpaueb/legal-bert-base-uncased')\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "texts = df['clean_text'].tolist()\n",
    "embeddings = model.encode(texts, batch_size=8, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nEmbeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:13:53.667765Z",
     "iopub.status.busy": "2025-11-24T21:13:53.667547Z",
     "iopub.status.idle": "2025-11-24T21:13:53.747431Z",
     "shell.execute_reply": "2025-11-24T21:13:53.746828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 14480 samples\n",
      "Test set: 3620 samples\n",
      "\n",
      "Training label distribution:\n",
      "0    13974\n",
      "1      506\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test label distribution:\n",
      "0    3493\n",
      "1     127\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['winlose'])\n",
    "\n",
    "# Split 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest label distribution:\")\n",
    "print(pd.Series(y_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train and Compare Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:13:53.749729Z",
     "iopub.status.busy": "2025-11-24T21:13:53.749548Z",
     "iopub.status.idle": "2025-11-24T21:17:47.839656Z",
     "shell.execute_reply": "2025-11-24T21:17:47.838821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training LogisticRegression...\n",
      "==================================================\n",
      "\n",
      "LogisticRegression Accuracy: 0.9845\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.99      0.99      0.99      3493\n",
      "         win       0.83      0.70      0.76       127\n",
      "\n",
      "    accuracy                           0.98      3620\n",
      "   macro avg       0.91      0.85      0.88      3620\n",
      "weighted avg       0.98      0.98      0.98      3620\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training RandomForest...\n",
      "==================================================\n",
      "\n",
      "RandomForest Accuracy: 0.9837\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.99      1.00      0.99      3493\n",
      "         win       0.83      0.67      0.74       127\n",
      "\n",
      "    accuracy                           0.98      3620\n",
      "   macro avg       0.91      0.83      0.87      3620\n",
      "weighted avg       0.98      0.98      0.98      3620\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training GradientBoosting...\n",
      "==================================================\n",
      "\n",
      "GradientBoosting Accuracy: 0.9843\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.99      0.99      0.99      3493\n",
      "         win       0.83      0.69      0.76       127\n",
      "\n",
      "    accuracy                           0.98      3620\n",
      "   macro avg       0.91      0.84      0.87      3620\n",
      "weighted avg       0.98      0.98      0.98      3620\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training SVC...\n",
      "==================================================\n",
      "\n",
      "SVC Accuracy: 0.9851\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.99      0.99      0.99      3493\n",
      "         win       0.79      0.78      0.79       127\n",
      "\n",
      "    accuracy                           0.99      3620\n",
      "   macro avg       0.89      0.89      0.89      3620\n",
      "weighted avg       0.98      0.99      0.99      3620\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training MLPClassifier...\n",
      "==================================================\n",
      "\n",
      "MLPClassifier Accuracy: 0.9848\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.99      1.00      0.99      3493\n",
      "         win       0.85      0.69      0.76       127\n",
      "\n",
      "    accuracy                           0.98      3620\n",
      "   macro avg       0.92      0.84      0.88      3620\n",
      "weighted avg       0.98      0.98      0.98      3620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models to test\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVC': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'MLPClassifier': MLPClassifier(hidden_layer_sizes=(256,), random_state=42, max_iter=500)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Select Best Model and Save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:17:47.846723Z",
     "iopub.status.busy": "2025-11-24T21:17:47.846614Z",
     "iopub.status.idle": "2025-11-24T21:17:48.187711Z",
     "shell.execute_reply": "2025-11-24T21:17:48.187434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Best Model: SVC\n",
      "Accuracy: 0.9851\n",
      "==================================================\n",
      "\n",
      "All artifacts saved to ../models\n",
      "\n",
      "Saved files:\n",
      "  - model.pkl\n",
      "  - label_encoder.pkl\n",
      "  - embeddings.npy\n",
      "  - clean_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_accuracy = results[best_model_name]['accuracy']\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Save model\n",
    "with open(MODELS_DIR / 'model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save label encoder\n",
    "with open(MODELS_DIR / 'label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Save embeddings\n",
    "np.save(MODELS_DIR / 'embeddings.npy', embeddings)\n",
    "\n",
    "# Save clean dataset\n",
    "df.to_csv(MODELS_DIR / 'clean_dataset.csv', index=False)\n",
    "\n",
    "print(f\"\\nAll artifacts saved to {MODELS_DIR}\")\n",
    "print(f\"\\nSaved files:\")\n",
    "print(f\"  - model.pkl\")\n",
    "print(f\"  - label_encoder.pkl\")\n",
    "print(f\"  - embeddings.npy\")\n",
    "print(f\"  - clean_dataset.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02bb3d040fed435787df3d57043c8677": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03564525ef4540aca2aff75e7652f31f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1c0ed4c20cb84e619f11eca87b550e91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3e81bd545a5d474fb06d2eb7037ca6f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b34e20667ae4bcc9dc4093f41a1eabb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a86e4d8f5fc14f8e8829f7f60f2245f3",
        "IPY_MODEL_6b4850646a474a6282ca719954a7c714",
        "IPY_MODEL_b1cff4a26a2e4fb0921fb5dd514e4c6f"
       ],
       "layout": "IPY_MODEL_d6bb484d2425487b82dd9e7f782deb77"
      }
     },
     "6b4850646a474a6282ca719954a7c714": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e81bd545a5d474fb06d2eb7037ca6f8",
       "max": 2263,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_03564525ef4540aca2aff75e7652f31f",
       "value": 2263
      }
     },
     "895af37a294747b69b927772a0d3aaff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f24345a190e49018b44357e35bd8e8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a86e4d8f5fc14f8e8829f7f60f2245f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_895af37a294747b69b927772a0d3aaff",
       "placeholder": "​",
       "style": "IPY_MODEL_1c0ed4c20cb84e619f11eca87b550e91",
       "value": "Batches: 100%"
      }
     },
     "b1cff4a26a2e4fb0921fb5dd514e4c6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_02bb3d040fed435787df3d57043c8677",
       "placeholder": "​",
       "style": "IPY_MODEL_8f24345a190e49018b44357e35bd8e8b",
       "value": " 2263/2263 [01:25&lt;00:00, 45.59it/s]"
      }
     },
     "d6bb484d2425487b82dd9e7f782deb77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
